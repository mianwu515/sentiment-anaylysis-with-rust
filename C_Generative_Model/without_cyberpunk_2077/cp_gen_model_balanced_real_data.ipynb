{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('all')\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "import sklearn as sk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(raw_data):\n",
    "    '''\n",
    "    This function takes in a string specifically \"cyberpunk\" and delete it.\n",
    "    '''\n",
    "    useful_words = raw_data.lower().split()\n",
    "    useful_words = [w.replace('cyberpunk', '') for w in useful_words]\n",
    "    return( \" \".join(useful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../B_Data_Cleaning/cleaned_real_reviews.csv\")\n",
    "df[\"Review\"] = df[\"Review\"].astype(\"str\")\n",
    "df['Review'] = df['Review'].apply(data_cleaning)\n",
    "df[\"Review\"] = df[\"Review\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Recommended or Not Recommended</th>\n",
       "      <th>Date Timestamp Created</th>\n",
       "      <th>set_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>day someone came ps version game quite journey...</td>\n",
       "      <td>True</td>\n",
       "      <td>1645046263</td>\n",
       "      <td>{brought, feature, alright, nitpicking, quests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>replay immediately demolish adam smasher</td>\n",
       "      <td>True</td>\n",
       "      <td>1663224196</td>\n",
       "      <td>{demolish, adam, replay, smasher, immediately}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patch fixed everything quests make sense fixer...</td>\n",
       "      <td>True</td>\n",
       "      <td>1645267750</td>\n",
       "      <td>{everything, way, reload, without, quests, fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>watches edgerunners downloads  time life</td>\n",
       "      <td>True</td>\n",
       "      <td>1667117035</td>\n",
       "      <td>{edgerunners, watches, life, downloads, time}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember hearing  around announced interested ...</td>\n",
       "      <td>True</td>\n",
       "      <td>1664423074</td>\n",
       "      <td>{show, everything, close, saw, cases, bad, lev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16455</th>\n",
       "      <td>boobs d</td>\n",
       "      <td>True</td>\n",
       "      <td>1608792512</td>\n",
       "      <td>{boobs, d}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16456</th>\n",
       "      <td>great main story  atmosphere good visuals slig...</td>\n",
       "      <td>True</td>\n",
       "      <td>1608792267</td>\n",
       "      <td>{game, story, outside, definitely, options, ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16457</th>\n",
       "      <td>got hardware run game definitely</td>\n",
       "      <td>True</td>\n",
       "      <td>1608777643</td>\n",
       "      <td>{game, got, hardware, definitely, run}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16458</th>\n",
       "      <td>glitches experience enough hold awesomeness ga...</td>\n",
       "      <td>True</td>\n",
       "      <td>1608777582</td>\n",
       "      <td>{game, experience, hold, patches, thisll, glit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16459</th>\n",
       "      <td>frankly dont negative press game amazing right...</td>\n",
       "      <td>True</td>\n",
       "      <td>1608770360</td>\n",
       "      <td>{regret, better, based, will, press, fun, amaz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16460 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  \\\n",
       "0      day someone came ps version game quite journey...   \n",
       "1               replay immediately demolish adam smasher   \n",
       "2      patch fixed everything quests make sense fixer...   \n",
       "3               watches edgerunners downloads  time life   \n",
       "4      remember hearing  around announced interested ...   \n",
       "...                                                  ...   \n",
       "16455                                            boobs d   \n",
       "16456  great main story  atmosphere good visuals slig...   \n",
       "16457                   got hardware run game definitely   \n",
       "16458  glitches experience enough hold awesomeness ga...   \n",
       "16459  frankly dont negative press game amazing right...   \n",
       "\n",
       "       Recommended or Not Recommended  Date Timestamp Created  \\\n",
       "0                                True              1645046263   \n",
       "1                                True              1663224196   \n",
       "2                                True              1645267750   \n",
       "3                                True              1667117035   \n",
       "4                                True              1664423074   \n",
       "...                               ...                     ...   \n",
       "16455                            True              1608792512   \n",
       "16456                            True              1608792267   \n",
       "16457                            True              1608777643   \n",
       "16458                            True              1608777582   \n",
       "16459                            True              1608770360   \n",
       "\n",
       "                                              set_column  \n",
       "0      {brought, feature, alright, nitpicking, quests...  \n",
       "1         {demolish, adam, replay, smasher, immediately}  \n",
       "2      {everything, way, reload, without, quests, fun...  \n",
       "3          {edgerunners, watches, life, downloads, time}  \n",
       "4      {show, everything, close, saw, cases, bad, lev...  \n",
       "...                                                  ...  \n",
       "16455                                         {boobs, d}  \n",
       "16456  {game, story, outside, definitely, options, ar...  \n",
       "16457             {game, got, hardware, definitely, run}  \n",
       "16458  {game, experience, hold, patches, thisll, glit...  \n",
       "16459  {regret, better, based, will, press, fun, amaz...  \n",
       "\n",
       "[16460 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a set_column to count the number of words in each review\n",
    "df[\"set_column\"] = df[\"Review\"].apply(lambda x: set(x.split()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 5250 reviews for each based on 'Recommended or Not Recommended\" column\n",
    "temp_recom = df.loc[df[\"Recommended or Not Recommended\"] == True,:]\n",
    "temp_recom = temp_recom.sample(5250).reset_index(drop=True)\n",
    "\n",
    "temp_not_recom = df.loc[df[\"Recommended or Not Recommended\"] == False,:]\n",
    "temp_not_recom = temp_not_recom.sample(5250).reset_index(drop=True)\n",
    "\n",
    "# combine temp_recom and temp_not_recom\n",
    "temp = pd.concat([temp_recom, temp_not_recom], axis=0).reset_index(drop=True)\n",
    "\n",
    "# split the data into train and test\n",
    "train, test = sk.model_selection.train_test_split(temp, test_size=0.33, random_state=42)\n",
    "\n",
    "# # split df_recom into train and test\n",
    "# df_recom = temp_recom.sample(frac=0.67, random_state=42).reset_index(drop=True)\n",
    "# test_recom = temp_recom.drop(df_recom.index).reset_index(drop=True)\n",
    "# print(f\"train size df_recom: {len(df_recom)}, test size df_recom: {len(test_recom)}\")\n",
    "\n",
    "# # split df_not_recom into train and test\n",
    "# df_not_recom = temp_not_recom.sample(frac=0.33, random_state=42).reset_index(drop=True)\n",
    "# test_not_recom = temp_not_recom.drop(df_not_recom.index).reset_index(drop=True)\n",
    "# print(f\"train size df_not_recom: {len(df_not_recom)}, test size df_not_recom: {len(test_not_recom)}\")\n",
    "\n",
    "# # combine test_recom and test_not_recom\n",
    "# test = pd.concat([test_recom, test_not_recom], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing dataset into recommended and not recommended\n",
    "df_recom = train.loc[train[\"Recommended or Not Recommended\"] == True,:]\n",
    "df_recom = df_recom.reset_index(drop=True)\n",
    "\n",
    "df_not_recom = train.loc[train[\"Recommended or Not Recommended\"] == False,:]\n",
    "df_not_recom = df_not_recom.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make the set dictionary\n",
    "# count how many times each word appears in the reviews\n",
    "bow_recom_temp = collections.Counter([y for x in df_recom.set_column for y in x])\n",
    "bow_not_recom_temp = collections.Counter([y for x in df_not_recom.set_column for y in x])\n",
    "\n",
    "bow_recom_set = dict(bow_recom_temp)\n",
    "bow_not_recom_set = dict(bow_not_recom_temp)\n",
    "\n",
    "for key in bow_recom_set:\n",
    "    if key not in bow_not_recom_set:\n",
    "        bow_not_recom_set[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_not_recom_set:\n",
    "    if key not in bow_recom_set:\n",
    "        bow_recom_set[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_recom_set:\n",
    "    bow_recom_set[key] += 1\n",
    "\n",
    "for key in bow_not_recom_set:\n",
    "    bow_not_recom_set[key] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make the list dictionary\n",
    "# count how many times each word appears in the reviews\n",
    "bow_recom = collections.Counter([y for x in df_recom.Review for y in x.split()])\n",
    "bow_not_recom = collections.Counter([y for x in df_not_recom.Review for y in x.split()])\n",
    "\n",
    "bow_recom_dict = dict(bow_recom)\n",
    "bow_not_recom_dict = dict(bow_not_recom)\n",
    "\n",
    "for key in bow_recom_dict:\n",
    "    if key not in bow_not_recom_dict:\n",
    "        bow_not_recom_dict[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_not_recom_dict:\n",
    "    if key not in bow_recom_dict:\n",
    "        bow_recom_dict[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_recom_dict:\n",
    "    bow_recom_dict[key] += 1\n",
    "\n",
    "for key in bow_not_recom_dict:\n",
    "    bow_not_recom_dict[key] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_recom_sum_vals = sum(bow_recom_dict.values())\n",
    "bow_not_recom_sum_vals = sum(bow_not_recom_dict.values())\n",
    "\n",
    "for i in bow_recom_dict:\n",
    "\n",
    "    bow_recom_dict[i] /= bow_recom_sum_vals\n",
    "\n",
    "for i in bow_not_recom_dict:\n",
    "\n",
    "    bow_not_recom_dict[i] /= bow_not_recom_sum_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bow_recom_dict) == len(bow_not_recom_dict)\n",
    "assert len(bow_recom_set) == len(bow_not_recom_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=[\"set_column\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sentiment(element, test_all=False, test_only_tf_abs=False, test_only_idf_abs=False, test_only_prob=False, test_all_abs=False):\n",
    "\n",
    "    \"\"\"This function takes a review and returns the label for that review\"\"\"\n",
    "\n",
    "    full_shape = df.shape[0]\n",
    "    positive_review_probabiliy = len(df_recom)/full_shape\n",
    "    negative_review_probabiliy = len(df_not_recom)/full_shape\n",
    "    \n",
    "    df_choices_positive = [positive_review_probabiliy, bow_recom_set, bow_recom_dict, df_recom]\n",
    "    df_choices_negative = [negative_review_probabiliy ,bow_not_recom_set, bow_not_recom_dict, df_not_recom]\n",
    "\n",
    "    def classifier(element, your_class = 'positive'):\n",
    "        flag = {}\n",
    "        flag_count = 0\n",
    "        if your_class == 'positive':\n",
    "            df_choices = df_choices_positive\n",
    "        else:\n",
    "            df_choices = df_choices_negative\n",
    "        prob_of_class = df_choices[0]/full_shape\n",
    "        score = 1 * prob_of_class\n",
    "        score = float(format(score, '.12f'))\n",
    "        # score = 0.1\n",
    "        for i in element.split():\n",
    "            if i not in df_choices[2].keys():\n",
    "                pass\n",
    "            else:\n",
    "                prob_word_given_class = (df_choices[2])[i]\n",
    "                prob_word_given_class = float(format(prob_word_given_class, '.12f'))\n",
    "                # Almost the same value, given our spin on this application. \n",
    "                # Normally, this term frequency would be calculated differently across the positive and negative documents\n",
    "                # but we are only looking at the reviews as the documents themselves to determine a word's relevance in the positive\n",
    "                # or negative corpus. \n",
    "                tf = np.log(prob_word_given_class)\n",
    "                # tf = float(format(tf, '.12f'))\n",
    "                # tf = abs(np.log(prob_word_given_class))\n",
    "                # The IDF is the number of reviews / the number of reviews that contain the word in that given corpus\n",
    "                # idf = abs(np.log(df_choices[3].shape[0]/(df_choices[1])[i]))\n",
    "                idf = np.log(df_choices[3].shape[0]/(df_choices[1])[i])\n",
    "                # idf = float(format(idf, '.12f'))\n",
    "                if test_all:\n",
    "                    score *= prob_word_given_class*tf*idf\n",
    "                elif test_only_tf_abs:\n",
    "                    score *= prob_word_given_class*tf\n",
    "                    score = abs(score)\n",
    "                elif test_only_idf_abs:\n",
    "                    score *= prob_word_given_class*idf\n",
    "                    score = abs(score)\n",
    "                elif test_only_prob:\n",
    "                    score *= prob_word_given_class\n",
    "                elif test_all_abs:\n",
    "                    score *= prob_word_given_class*tf*idf\n",
    "                    score = abs(score)\n",
    "\n",
    "                if score < 0:\n",
    "                    flag[flag_count] = (score, your_class)\n",
    "                    # print(flag_count,i)\n",
    "                    flag_count += 1\n",
    "                    # return 'Flag'\n",
    "\n",
    "\n",
    "        return score\n",
    "    positive_score = classifier(element, 'positive')\n",
    "    negative_score = classifier(element, 'negative')\n",
    "    if positive_score > negative_score:\n",
    "        return True\n",
    "    elif positive_score == negative_score:\n",
    "        # Choosing an arbitrary value, because we assume that a review with one or few words of little substance\n",
    "        # is implied to be negative, as is usual with netizens. \n",
    "        return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"score_all\"] = test.Review.apply(define_sentiment, test_all=True)\n",
    "test[\"score_tf\"] = test.Review.apply(define_sentiment, test_only_tf_abs=True)\n",
    "test[\"score_idf\"] = test.Review.apply(define_sentiment, test_only_idf_abs=True)\n",
    "test[\"score_freq\"] = test.Review.apply(define_sentiment, test_only_prob=True)\n",
    "test[\"score_mod_all\"] = test.Review.apply(define_sentiment, test_all_abs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result without the word 'cyberpunk' included in the corpus:\n",
      "This is our accuracy for (balanced) real data with all the formula: 51.83%\n",
      "This is our accuracy for (balanced) real data with only class probability, frequency, and absolute value of TF: 76.77%\n",
      "This is our accuracy for (balanced) real data with only class probability, frequency, and absolute value of IDF: 70.53%\n",
      "This is our accuracy for (balanced) real data with only class probability and frequency: 75.47%\n",
      "This is our accuracy for (balanced) real data with all the formula, but with the absolute value of the score: 69.29%\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the result without the word 'cyberpunk' included in the corpus:\")\n",
    "print(f\"This is our accuracy for (balanced) real data with all the formula: {(sum(test['Recommended or Not Recommended'] == test['score_all'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) real data with only class probability, frequency, and absolute value of TF: {(sum(test['Recommended or Not Recommended'] == test['score_tf'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) real data with only class probability, frequency, and absolute value of IDF: {(sum(test['Recommended or Not Recommended'] == test['score_idf'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) real data with only class probability and frequency: {(sum(test['Recommended or Not Recommended'] == test['score_freq'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) real data with all the formula, but with the absolute value of the score: {(sum(test['Recommended or Not Recommended'] == test['score_mod_all'])/test.shape[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.60      0.55      1699\n",
      "        True       0.53      0.44      0.48      1766\n",
      "\n",
      "    accuracy                           0.52      3465\n",
      "   macro avg       0.52      0.52      0.52      3465\n",
      "weighted avg       0.52      0.52      0.52      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_all'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_all']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.85      0.78      1699\n",
      "        True       0.83      0.68      0.75      1766\n",
      "\n",
      "    accuracy                           0.77      3465\n",
      "   macro avg       0.78      0.77      0.77      3465\n",
      "weighted avg       0.78      0.77      0.77      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_tf'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_tf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.63      0.68      1699\n",
      "        True       0.69      0.78      0.73      1766\n",
      "\n",
      "    accuracy                           0.71      3465\n",
      "   macro avg       0.71      0.70      0.70      3465\n",
      "weighted avg       0.71      0.71      0.70      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_idf'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_idf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.70      0.86      0.77      1699\n",
      "        True       0.83      0.65      0.73      1766\n",
      "\n",
      "    accuracy                           0.75      3465\n",
      "   macro avg       0.77      0.76      0.75      3465\n",
      "weighted avg       0.77      0.75      0.75      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_freq'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_freq']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
