{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "# nltk.download('all')\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "import sklearn as sk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(raw_data):\n",
    "    '''\n",
    "    This function takes in a string specifically \"cyberpunk\" and delete it.\n",
    "    '''\n",
    "    useful_words = raw_data.lower().split()\n",
    "    useful_words = [w.replace('cyberpunk', '') for w in useful_words]\n",
    "    return( \" \".join(useful_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../B_Data_Cleaning/synthetic_reviews_all_trial_1.csv\")\n",
    "df[\"Review\"] = df[\"Review\"].astype(\"str\")\n",
    "df['Review'] = df['Review'].apply(data_cleaning)\n",
    "df[\"Review\"] = df[\"Review\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Recommended or Not Recommended</th>\n",
       "      <th>set_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idols hex scifistoryelements airborne underwor...</td>\n",
       "      <td>True</td>\n",
       "      <td>{sandwish, storry, neondiarrhea, artistically,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablazing ｉｔｓ alanah дрянь ammunition unbreakab...</td>\n",
       "      <td>True</td>\n",
       "      <td>{mau, highrises, göre, узнать, adjusting, cohe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>doubletapping overcrowded critiquer minesweepe...</td>\n",
       "      <td>True</td>\n",
       "      <td>{transição, orçamento, ruleset, crates, entail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>puffing mild miniboss vybouchnou selected bonl...</td>\n",
       "      <td>True</td>\n",
       "      <td>{maniacs, kaoru, 월등하게, citizenscops, wham, rai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rapid bpoliceb seeen contagion whazoo</td>\n",
       "      <td>True</td>\n",
       "      <td>{rapid, whazoo, seeen, bpoliceb, contagion}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16570</th>\n",
       "      <td>gathering acording damagedealing hquests guide...</td>\n",
       "      <td>False</td>\n",
       "      <td>{humanityethics, buggyness, exploitation, ashe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16571</th>\n",
       "      <td>ghameplay houdini viks chews planed ao corpotr...</td>\n",
       "      <td>False</td>\n",
       "      <td>{touch, exploitation, unrealized, karaoke, unn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16572</th>\n",
       "      <td>oldgen excelentes httpswwwyoutubecomwatchvzfrc...</td>\n",
       "      <td>False</td>\n",
       "      <td>{battlegun, aynı, customizável, lasts, somethi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16573</th>\n",
       "      <td>preferência fixespolish compli platoon caminan...</td>\n",
       "      <td>False</td>\n",
       "      <td>{unaccetable, entail, strat, countersteering, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16574</th>\n",
       "      <td>astronomical boards httpsyoutubetowfeueaeeqt p...</td>\n",
       "      <td>False</td>\n",
       "      <td>{ride, sitcom, multitiered, buggyness, keys, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16575 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  \\\n",
       "0      idols hex scifistoryelements airborne underwor...   \n",
       "1      ablazing ｉｔｓ alanah дрянь ammunition unbreakab...   \n",
       "2      doubletapping overcrowded critiquer minesweepe...   \n",
       "3      puffing mild miniboss vybouchnou selected bonl...   \n",
       "4                  rapid bpoliceb seeen contagion whazoo   \n",
       "...                                                  ...   \n",
       "16570  gathering acording damagedealing hquests guide...   \n",
       "16571  ghameplay houdini viks chews planed ao corpotr...   \n",
       "16572  oldgen excelentes httpswwwyoutubecomwatchvzfrc...   \n",
       "16573  preferência fixespolish compli platoon caminan...   \n",
       "16574  astronomical boards httpsyoutubetowfeueaeeqt p...   \n",
       "\n",
       "       Recommended or Not Recommended  \\\n",
       "0                                True   \n",
       "1                                True   \n",
       "2                                True   \n",
       "3                                True   \n",
       "4                                True   \n",
       "...                               ...   \n",
       "16570                           False   \n",
       "16571                           False   \n",
       "16572                           False   \n",
       "16573                           False   \n",
       "16574                           False   \n",
       "\n",
       "                                              set_column  \n",
       "0      {sandwish, storry, neondiarrhea, artistically,...  \n",
       "1      {mau, highrises, göre, узнать, adjusting, cohe...  \n",
       "2      {transição, orçamento, ruleset, crates, entail...  \n",
       "3      {maniacs, kaoru, 월등하게, citizenscops, wham, rai...  \n",
       "4            {rapid, whazoo, seeen, bpoliceb, contagion}  \n",
       "...                                                  ...  \n",
       "16570  {humanityethics, buggyness, exploitation, ashe...  \n",
       "16571  {touch, exploitation, unrealized, karaoke, unn...  \n",
       "16572  {battlegun, aynı, customizável, lasts, somethi...  \n",
       "16573  {unaccetable, entail, strat, countersteering, ...  \n",
       "16574  {ride, sitcom, multitiered, buggyness, keys, c...  \n",
       "\n",
       "[16575 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a set_column to count the number of words in each review\n",
    "df[\"set_column\"] = df[\"Review\"].apply(lambda x: set(x.split()))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only 5250 reviews for each based on 'Recommended or Not Recommended\" column\n",
    "temp_recom = df.loc[df[\"Recommended or Not Recommended\"] == True,:]\n",
    "temp_recom = temp_recom.sample(5250).reset_index(drop=True)\n",
    "\n",
    "temp_not_recom = df.loc[df[\"Recommended or Not Recommended\"] == False,:]\n",
    "temp_not_recom = temp_not_recom.sample(5250).reset_index(drop=True)\n",
    "\n",
    "# combine temp_recom and temp_not_recom\n",
    "temp = pd.concat([temp_recom, temp_not_recom], axis=0).reset_index(drop=True)\n",
    "\n",
    "# split the data into train and test\n",
    "train, test = sk.model_selection.train_test_split(temp, test_size=0.33, random_state=42)\n",
    "\n",
    "# # split df_recom into train and test\n",
    "# df_recom = temp_recom.sample(frac=0.67, random_state=42).reset_index(drop=True)\n",
    "# test_recom = temp_recom.drop(df_recom.index).reset_index(drop=True)\n",
    "# print(f\"train size df_recom: {len(df_recom)}, test size df_recom: {len(test_recom)}\")\n",
    "\n",
    "# # split df_not_recom into train and test\n",
    "# df_not_recom = temp_not_recom.sample(frac=0.33, random_state=42).reset_index(drop=True)\n",
    "# test_not_recom = temp_not_recom.drop(df_not_recom.index).reset_index(drop=True)\n",
    "# print(f\"train size df_not_recom: {len(df_not_recom)}, test size df_not_recom: {len(test_not_recom)}\")\n",
    "\n",
    "# # combine test_recom and test_not_recom\n",
    "# test = pd.concat([test_recom, test_not_recom], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing dataset into recommended and not recommended\n",
    "df_recom = train.loc[train[\"Recommended or Not Recommended\"] == True,:]\n",
    "df_recom = df_recom.reset_index(drop=True)\n",
    "\n",
    "df_not_recom = train.loc[train[\"Recommended or Not Recommended\"] == False,:]\n",
    "df_not_recom = df_not_recom.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make the set dictionary\n",
    "# count how many times each word appears in the reviews\n",
    "bow_recom_temp = collections.Counter([y for x in df_recom.set_column for y in x])\n",
    "bow_not_recom_temp = collections.Counter([y for x in df_not_recom.set_column for y in x])\n",
    "\n",
    "bow_recom_set = dict(bow_recom_temp)\n",
    "bow_not_recom_set = dict(bow_not_recom_temp)\n",
    "\n",
    "for key in bow_recom_set:\n",
    "    if key not in bow_not_recom_set:\n",
    "        bow_not_recom_set[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_not_recom_set:\n",
    "    if key not in bow_recom_set:\n",
    "        bow_recom_set[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_recom_set:\n",
    "    bow_recom_set[key] += 1\n",
    "\n",
    "for key in bow_not_recom_set:\n",
    "    bow_not_recom_set[key] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to make the list dictionary\n",
    "# count how many times each word appears in the reviews\n",
    "bow_recom = collections.Counter([y for x in df_recom.Review for y in x.split()])\n",
    "bow_not_recom = collections.Counter([y for x in df_not_recom.Review for y in x.split()])\n",
    "\n",
    "bow_recom_dict = dict(bow_recom)\n",
    "bow_not_recom_dict = dict(bow_not_recom)\n",
    "\n",
    "for key in bow_recom_dict:\n",
    "    if key not in bow_not_recom_dict:\n",
    "        bow_not_recom_dict[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_not_recom_dict:\n",
    "    if key not in bow_recom_dict:\n",
    "        bow_recom_dict[key] = 0\n",
    "        pass\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for key in bow_recom_dict:\n",
    "    bow_recom_dict[key] += 1\n",
    "\n",
    "for key in bow_not_recom_dict:\n",
    "    bow_not_recom_dict[key] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_recom_sum_vals = sum(bow_recom_dict.values())\n",
    "bow_not_recom_sum_vals = sum(bow_not_recom_dict.values())\n",
    "\n",
    "for i in bow_recom_dict:\n",
    "\n",
    "    bow_recom_dict[i] /= bow_recom_sum_vals\n",
    "\n",
    "for i in bow_not_recom_dict:\n",
    "\n",
    "    bow_not_recom_dict[i] /= bow_not_recom_sum_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(bow_recom_dict) == len(bow_not_recom_dict)\n",
    "assert len(bow_recom_set) == len(bow_not_recom_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=[\"set_column\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_sentiment(element, test_all=False, test_only_tf_abs=False, test_only_idf_abs=False, test_only_prob=False, test_all_abs=False):\n",
    "\n",
    "    \"\"\"This function takes a review and returns the label for that review\"\"\"\n",
    "\n",
    "    full_shape = df.shape[0]\n",
    "    positive_review_probabiliy = len(df_recom)/full_shape\n",
    "    negative_review_probabiliy = len(df_not_recom)/full_shape\n",
    "    \n",
    "    df_choices_positive = [positive_review_probabiliy, bow_recom_set, bow_recom_dict, df_recom]\n",
    "    df_choices_negative = [negative_review_probabiliy ,bow_not_recom_set, bow_not_recom_dict, df_not_recom]\n",
    "\n",
    "    def classifier(element, your_class = 'positive'):\n",
    "        flag = {}\n",
    "        flag_count = 0\n",
    "        if your_class == 'positive':\n",
    "            df_choices = df_choices_positive\n",
    "        else:\n",
    "            df_choices = df_choices_negative\n",
    "        prob_of_class = df_choices[0]/full_shape\n",
    "        score = 1 * prob_of_class\n",
    "        score = float(format(score, '.12f'))\n",
    "        # score = 0.1\n",
    "        for i in element.split():\n",
    "            if i not in df_choices[2].keys():\n",
    "                pass\n",
    "            else:\n",
    "                prob_word_given_class = (df_choices[2])[i]\n",
    "                prob_word_given_class = float(format(prob_word_given_class, '.12f'))\n",
    "                # Almost the same value, given our spin on this application. \n",
    "                # Normally, this term frequency would be calculated differently across the positive and negative documents\n",
    "                # but we are only looking at the reviews as the documents themselves to determine a word's relevance in the positive\n",
    "                # or negative corpus. \n",
    "                tf = np.log(prob_word_given_class)\n",
    "                # tf = float(format(tf, '.12f'))\n",
    "                # tf = abs(np.log(prob_word_given_class))\n",
    "                # The IDF is the number of reviews / the number of reviews that contain the word in that given corpus\n",
    "                # idf = abs(np.log(df_choices[3].shape[0]/(df_choices[1])[i]))\n",
    "                idf = np.log(df_choices[3].shape[0]/(df_choices[1])[i])\n",
    "                # idf = float(format(idf, '.12f'))\n",
    "                if test_all:\n",
    "                    score *= prob_word_given_class*tf*idf\n",
    "                elif test_only_tf_abs:\n",
    "                    score *= prob_word_given_class*tf\n",
    "                    score = abs(score)\n",
    "                elif test_only_idf_abs:\n",
    "                    score *= prob_word_given_class*idf\n",
    "                    score = abs(score)\n",
    "                elif test_only_prob:\n",
    "                    score *= prob_word_given_class\n",
    "                elif test_all_abs:\n",
    "                    score *= prob_word_given_class*tf*idf\n",
    "                    score = abs(score)\n",
    "\n",
    "                if score < 0:\n",
    "                    flag[flag_count] = (score, your_class)\n",
    "                    # print(flag_count,i)\n",
    "                    flag_count += 1\n",
    "                    # return 'Flag'\n",
    "\n",
    "\n",
    "        return score\n",
    "    positive_score = classifier(element, 'positive')\n",
    "    negative_score = classifier(element, 'negative')\n",
    "    if positive_score > negative_score:\n",
    "        return True\n",
    "    elif positive_score == negative_score:\n",
    "        # Choosing an arbitrary value, because we assume that a review with one or few words of little substance\n",
    "        # is implied to be negative, as is usual with netizens. \n",
    "        return False\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"score_all\"] = test.Review.apply(define_sentiment, test_all=True)\n",
    "test[\"score_tf\"] = test.Review.apply(define_sentiment, test_only_tf_abs=True)\n",
    "test[\"score_idf\"] = test.Review.apply(define_sentiment, test_only_idf_abs=True)\n",
    "test[\"score_freq\"] = test.Review.apply(define_sentiment, test_only_prob=True)\n",
    "test[\"score_mod_all\"] = test.Review.apply(define_sentiment, test_all_abs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result without the word 'cyberpunk' included in the corpus:\n",
      "This is our accuracy for (balanced) synthetic data with all the formula: 51.02%\n",
      "This is our accuracy for (balanced) synthetic data with only class probability, frequency, and absolute value of TF: 87.73%\n",
      "This is our accuracy for (balanced) synthetic data with only class probability, frequency, and absolute value of IDF: 87.24%\n",
      "This is our accuracy for (balanced) synthetic data with only class probability and frequency: 85.17%\n",
      "This is our accuracy for (balanced) synthetic data with all the formula, but with the absolute value of the score: 89.96%\n"
     ]
    }
   ],
   "source": [
    "print(\"This is the result without the word 'cyberpunk' included in the corpus:\")\n",
    "print(f\"This is our accuracy for (balanced) synthetic data with all the formula: {(sum(test['Recommended or Not Recommended'] == test['score_all'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) synthetic data with only class probability, frequency, and absolute value of TF: {(sum(test['Recommended or Not Recommended'] == test['score_tf'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) synthetic data with only class probability, frequency, and absolute value of IDF: {(sum(test['Recommended or Not Recommended'] == test['score_idf'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) synthetic data with only class probability and frequency: {(sum(test['Recommended or Not Recommended'] == test['score_freq'])/test.shape[0])*100:.2f}%\")\n",
    "print(f\"This is our accuracy for (balanced) synthetic data with all the formula, but with the absolute value of the score: {(sum(test['Recommended or Not Recommended'] == test['score_mod_all'])/test.shape[0])*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.62      0.55      1699\n",
      "        True       0.53      0.41      0.46      1766\n",
      "\n",
      "    accuracy                           0.51      3465\n",
      "   macro avg       0.51      0.51      0.51      3465\n",
      "weighted avg       0.51      0.51      0.51      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_all'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_all']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.99      0.89      1699\n",
      "        True       0.99      0.77      0.86      1766\n",
      "\n",
      "    accuracy                           0.88      3465\n",
      "   macro avg       0.90      0.88      0.88      3465\n",
      "weighted avg       0.90      0.88      0.88      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_tf'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_tf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.99      0.88      1699\n",
      "        True       0.98      0.76      0.86      1766\n",
      "\n",
      "    accuracy                           0.87      3465\n",
      "   macro avg       0.89      0.87      0.87      3465\n",
      "weighted avg       0.89      0.87      0.87      3465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_idf'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_idf']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.77      0.99      0.87      1699\n",
      "        True       0.99      0.72      0.83      1766\n",
      "\n",
      "    accuracy                           0.85      3465\n",
      "   macro avg       0.88      0.85      0.85      3465\n",
      "weighted avg       0.88      0.85      0.85      3465\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b':O\\xfd\\x90\\xd7R=\\xfa\\x0f\\x80g\\x04\\xdd\\x8c\\xd66w\\xb9 \\x9a\\xb8%))7]\\xcc\\x90&\\xfd%\\x7f\\xae\\xfa\\x1fT\\xd9\\xa8\\x0e\\xc7\\xd9\\xf11\"\\x83M\\x83\\xe3\\xe0f!\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x00\\x1e\\x00\\x1c\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\\x08\\x04\\x08\\x05\\x08\\x06\\x04\\x01\\x05\\x01\\x06\\x01\\x00+\\x00\\x03\\x02\\x03\\x04\\x00-\\x00\\x02\\x01\\x01\\x003\\x00&\\x00$\\x00\\x1d\\x00 :\\xb9|.\\x063\\'I}\\no']\n",
      "Bad pipe message: %s [b\"\\xb1\\xaa\\xbe)\\xc9'*\\xa3f\\xba)4\\xf912\\xe0\\x96\\xda \\xcd\\xc19\\x02\\xde\\xb9\\x80\\x08\\xda\\x11\\xd5\\xce\\xed\"]\n",
      "Bad pipe message: %s [b'\\xd4\\x0cNZ\\xc8?\\xf1j5\\xc0\\xc7\\xf3\\x9d', b\"v\\xf71\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x0c\\x00\\n\\x00\\x1d\\x00\\x17\\x00\\x1e\\x00\\x19\\x00\\x18\\x00#\\x00\\x00\\x00\\x16\\x00\\x00\\x00\\x17\\x00\\x00\\x00\\r\\x000\\x00.\\x04\\x03\\x05\\x03\\x06\\x03\\x08\\x07\\x08\\x08\\x08\\t\\x08\\n\\x08\\x0b\"]\n",
      "Bad pipe message: %s [b'\\x08\\x05\\x08\\x06\\x04\\x01\\x05']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x03\\x03']\n",
      "Bad pipe message: %s [b'']\n",
      "Bad pipe message: %s [b'', b'\\x02']\n",
      "Bad pipe message: %s [b'\\x05\\x02\\x06']\n",
      "Bad pipe message: %s [b'\\xc9\\xa1m\\xf5\\xac^H\\xfdy\\xb8\\xa8\\xad\\xf0h\\x9a\\x0c\\xcd\\xcd\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\\x00\\x04\\x03\\x00\\x01\\x02']\n",
      "Bad pipe message: %s [b'@\\xe7g\\xe3D\\xdd\\xa0\\x93g\\xfd\\x07\\xe2\\x04\\x03\\xd0\\x01\\xd5Y\\x00\\x00>\\xc0\\x14\\xc0']\n",
      "Bad pipe message: %s [b'9\\x008\\x007\\x006\\xc0\\x0f']\n",
      "Bad pipe message: %s [b'J\\x12U\"\\x14\\x96/\\xcd\\xaf\\xf9oX\\x1d\\xef\\xff\\xd8\\xc7\\xc5\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00', b'\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00\\x1a\\x00\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15']\n",
      "Bad pipe message: %s [b'\\x1b\\xf9\\xd2\\xce\\xa0\\x8d\\x97\\xb99\\x07\\xd0\\xd2\\\\\\xe2\\xf3\\x7f\\x9a\\x93\\x00\\x00\\x86\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\xc0/\\xc0']\n",
      "Bad pipe message: %s [b\"'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x9c\\x00<']\n",
      "Bad pipe message: %s [b'\\x08\\xe8\\xaf\\xc9\\x9c89?\\x185\\x83\\x92}#\\x8a\\xa8\\xec\\x81\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0']\n",
      "Bad pipe message: %s [b'\\xa5\\x00\\xa3\\x00\\xa1\\x00\\x9f\\x00k']\n"
     ]
    }
   ],
   "source": [
    "# Generate a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test['Recommended or Not Recommended'], test['score_freq'])\n",
    "# Generate a classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test['Recommended or Not Recommended'], test['score_freq']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
